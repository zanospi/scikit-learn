.. include:: _contributors.rst

.. currentmodule:: sklearn

.. _changes_0_21:

Version 0.21.0
==============

**In development**

Changed models
--------------

The following estimators and functions, when fit with the same data and
parameters, may produce different models from the previous version. This often
occurs due to changes in the modelling logic (bug fixes or enhancements), or in
random sampling procedures.

- :class:`linear_model.BayesianRidge` |Fix|
- Decision trees and derived ensembles when both `max_depth` and
  `max_leaf_nodes` are set. |Fix|
- :class:`linear_model.LogisticRegression` and
  :class:`linear_model.LogisticRegressionCV` with 'saga' solver. |Fix|
- :class:`ensemble.GradientBoostingClassifier` for multiclass
  classification. |Fix|
- :func:`svm.SVC.decision_function` and
  :func:`multiclass.OneVsOneClassifier.decision_function`. |Fix|


Details are listed in the changelog below.

(While we are trying to better inform users by providing this information, we
cannot assure that this list is complete.)

Changelog
---------

Support for Python 3.4 and below has been officially dropped.

..
    See version doc/whats_new/v0.20.rst for structure. Entries should be
    prefixed with one of the labels: |MajorFeature|, |Feature|, |Efficiency|,
    |Enhancement|, |Fix| or |API|. They should be under a heading for the
    relevant module (or *Multiple Modules* or *Miscellaneous*), and within each
    section should be ordered according to the label ordering above. Entries
    should end with: :issue:`123456` by :user:`Joe Bloggs <joeongithub>`.

:mod:`sklearn.calibration`
..........................

- |Enhancement| Added support to bin the data passed into
  :class:`calibration.calibration_curve` by quantiles instead of uniformly
  between 0 and 1.
  :issue:`13086` by :user:`Scott Cole <srcole>`.

:mod:`sklearn.cluster`
......................

- |MajorFeature| A new clustering algorithm: :class:`cluster.OPTICS`: an
  algoritm related to :class:`cluster.DBSCAN`, that has hyperparameters easier
  to set and that scales better, by :user:`Shane <espg>`,
  :user:`Adrin Jalali <adrinjalali>`, and :user:`Erich Schubert <kno10>`.

- |API| Changing the parameter pattern in :class:`cluster.DBSCAN` from
  ``metric = euclidean`` to ``metric = minkowski``. In addition to creating the
  parameter ``p = 2``. This p is that it should be possible to switch between
  Manhattan and Euclidian and other Minkowski distances just by modifying
  ``'p'`` (without changing metric).
  :issue:`12437` by :user:`Gilberto Olimpio <gilbertoolimpio>`

:mod:`sklearn.datasets`
.......................

- |Fix| Added support for 64-bit group IDs and pointers in SVMLight files
  :class:`datasets.svmlight_format` :issue:`10727` by
  :user:`Bryan K Woods <bryan-woods>`.

- |Fix| :func:`datasets.load_sample_images` returns images with a deterministic
  order. :issue:`13250` by :user:`Thomas Fan <thomasjpfan>`.

:mod:`sklearn.decomposition`
............................

- |API| The default value of the :code:`init` argument in
  :func:`decomposition.non_negative_factorization` will change from
  :code:`random` to :code:`None` in version 0.23 to make it consistent with
  :class:`decomposition.NMF`. A FutureWarning is raised when
  the default value is used.
  :issue:`12988` by :user:`Zijie (ZJ) Poh <zjpoh>`.

- |Fix| Fixed a bug in :class:`decomposition.NMF` where `init = 'nndsvd'`,
  `init = 'nndsvda'`, and `init = 'nndsvdar'` are allowed when
  `n_components < n_features` instead of
  `n_components <= min(n_samples, n_features)`.
  :issue:`11650` by :user:`Hossein Pourbozorg <hossein-pourbozorg>` and
  :user:`Zijie (ZJ) Poh <zjpoh>`.

- |Enhancement| :class:`decomposition.KernelPCA` now has deterministic output 
  (resolved sign ambiguity in eigenvalue decomposition of the kernel matrix).
  :issue:`13241` by :user:`Aur√©lien Bellet <bellet>`.

:mod:`sklearn.discriminant_analysis`
....................................

- |Enhancement| :class:`discriminant_analysis.LinearDiscriminantAnalysis` now
  preserves ``float32`` and ``float64`` dtypes. :issues:`8769` and
  :issues:`11000` by :user:`Thibault Sejourne <thibsej>`

- |Fix| A ``ChangedBehaviourWarning`` is now raised when
  :class:`discriminant_analysis.LinearDiscriminantAnalysis` is given as
  parameter ``n_components > min(n_features, n_classes - 1)``, and
  ``n_components`` is changed to ``min(n_features, n_classes - 1)`` if so.
  Previously the change was made, but silently. :issue:`11526` by
  :user:`William de Vazelhes<wdevazelhes>`.
  
:mod:`sklearn.dummy`
....................

- |Fix| Fixed a bug in :class:`dummy.DummyClassifier` where the
  ``predict_proba`` method was returning int32 array instead of
  float64 for the ``stratified`` strategy. :issue:`13266` by
  :user:`Christos Aridas<chkoar>`.

:mod:`sklearn.ensemble`
.......................

- |Efficiency| Make :class:`ensemble.IsolationForest` prefer threads over
  processes when running with ``n_jobs > 1`` as the underlying decision tree
  fit calls do release the GIL. This changes reduces memory usage and
  communication overhead. :issue:`12543` by :user:`Isaac Storch <istorch>`
  and `Olivier Grisel`_.

- |Fix| Fixed the output of the average path length computed in
  :class:`ensemble.IsolationForest` when the input is either 0, 1 or 2.
  :issue:`13251` by :user:`Albert Thomas <albertcthomas>`
  and :user:`joshuakennethjones <joshuakennethjones>`.

- |Fix| Fixed a bug in :class:`ensemble.GradientBoostingClassifier` where
  the gradients would be incorrectly computed in multiclass classification
  problems. :issue:`12715` by :user:`Nicolas Hug<NicolasHug>`.

- |Fix| Fixed a bug in :mod:`ensemble` where the ``predict`` method would
  error for multiclass multioutput forests models if any targets were strings.
  :issue:`12834` by :user:`Elizabeth Sander <elsander>`.

- |Fix| Fixed a bug in :class:`ensemble.gradient_boosting.LossFunction` and
  :class:`ensemble.gradient_boosting.LeastSquaresError` where the default
  value of ``learning_rate`` in ``update_terminal_regions`` is not consistent
  with the document and the caller functions.
  :issue:`6463` by :user:`movelikeriver <movelikeriver>`.
  
- |Enhancement| Minimized the validation of X in
  :class:`ensemble.AdaBoostClassifier` and :class:`ensemble.AdaBoostRegressor`
  :issue:`13174` by :user:`Christos Aridas <chkoar>`.

:mod:`sklearn.externals`
........................

- |API| Deprecated :mod:`externals.six` since we have dropped support for
  Python 2.7. :issue:`12916` by :user:`Hanmin Qin <qinhanmin2014>`.

:mod:`sklearn.impute`
.....................

- |MajorFeature| Added :class:`impute.IterativeImputer`, which is a strategy
  for imputing missing values by modeling each feature with missing values as a
  function of other features in a round-robin fashion. :issue:`8478` and
  :issue:`12177` by :user:`Sergey Feldman <sergeyf>` :user:`Ben Lawson
  <benlawson>`.

- |Fix| In :class:`impute.MissingIndicator` avoid implicit densification by
  raising an exception if input is sparse add `missing_values` property
  is set to 0. :issue:`13240` by :user:`Bartosz Telenczuk <btel>`.

:mod:`sklearn.linear_model`
...........................

- |Enhancement| :class:`linear_model.make_dataset` now preserves
  ``float32`` and ``float64`` dtypes. :issues:`8769` and :issues:`11000` by
  :user:`Nelle Varoquaux`_, :user:`Arthur Imbert <Henley13>`,
  :user:`Guillaume Lemaitre <glemaitre>`, and :user:`Joan Massich <massich>`

- |Feature| :class:`linear_model.LogisticRegression` and
  :class:`linear_model.LogisticRegressionCV` now support Elastic-Net penalty,
  with the 'saga' solver. :issue:`11646` by :user:`Nicolas Hug <NicolasHug>`.

- |Enhancement| :class:`linear_model.LogisticRegression` now supports an
  unregularized objective by setting ``penalty`` to ``'none'``. This is
  equivalent to setting ``C=np.inf`` with l2 regularization. Not supported
  by the liblinear solver. :issue:`12860` by :user:`Nicolas Hug
  <NicolasHug>`.

- |Fix| Fixed a bug in :class:`linear_model.LogisticRegression` and
  :class:`linear_model.LogisticRegressionCV` with 'saga' solver, where the
  weights would not be correctly updated in some cases.
  :issue:`11646` by `Tom Dupre la Tour`_.

- |Fix| Fixed the posterior mean, posterior covariance and returned
  regularization parameters in :class:`linear_model.BayesianRidge`. The
  posterior mean and the posterior covariance were not the ones computed
  with the last update of the regularization parameters and the returned
  regularization parameters were not the final ones. Also fixed the formula of
  the log marginal likelihood used to compute the score when
  `compute_score=True`. :issue:`12174` by
  :user:`Albert Thomas <albertcthomas>`.

- |API| :func:`linear_model.logistic_regression_path` is deprecated
  in version 0.21 and will be removed in version 0.23.
  :issue:`12821` by :user:`Nicolas Hug <NicolasHug>`.

- |Fix| Fixed a bug in :class:`linear_model.LassoLarsIC`, where user input
   ``copy_X=False`` at instance creation would be overridden by default
   parameter value ``copy_X=True`` in ``fit``.
   :issue:`12972` by :user:`Lucio Fernandez-Arjona <luk-f-a>`

- |Fix| Fixed a bug in :class:`linear_model.LinearRegression` that
  was not returning the same coeffecients and intercepts with
  ``fit_intercept=True`` in sparse and dense case.
  :issue:`13279` by `Alexandre Gramfort`_

:mod:`sklearn.manifold`
............................

- |Efficiency| Make :func:`manifold.tsne.trustworthiness` use an inverted index
  instead of an `np.where` lookup to find the rank of neighbors in the input
  space. This improves efficiency in particular when computed with
  lots of neighbors and/or small datasets.
  :issue:`9907` by :user:`William de Vazelhes <wdevazelhes>`.

:mod:`sklearn.metrics`
......................

- |Efficiency| Faster :func:`metrics.pairwise.pairwise_distances` with `n_jobs`
  > 1 by using a thread-based backend, instead of process-based backends.
  :issue:`8216` by :user:`Pierre Glaser <pierreglaser>` and
  :user:`Romuald Menuet <zanospi>`

- |Feature| Added the :func:`metrics.max_error` metric and a corresponding
  ``'max_error'`` scorer for single output regression.
  :issue:`12232` by :user:`Krishna Sangeeth <whiletruelearn>`.

- |Feature| Add :func:`metrics.multilabel_confusion_matrix`, which calculates a
  confusion matrix with true positive, false positive, false negative and true
  negative counts for each class. This facilitates the calculation of set-wise
  metrics such as recall, specificity, fall out and miss rate.
  :issue:`11179` by :user:`Shangwu Yao <ShangwuYao>` and `Joel Nothman`_.

- |Enhancement| Use label `accuracy` instead of `micro-average` on
  :func:`metrics.classification_report` to avoid confusion. `micro-average` is
  only shown for multi-label or multi-class with a subset of classes because
  it is otherwise identical to accuracy.
  :issue:`12334` by :user:`Emmanuel Arias <eamanu@eamanu.com>`,
  `Joel Nothman`_ and `Andreas M√ºller`_

- |API| The parameter ``labels`` in :func:`metrics.hamming_loss` is deprecated
  in version 0.21 and will be removed in version 0.23.
  :issue:`10580` by :user:`Reshama Shaikh <reshamas>` and `Sandra
  Mitrovic <SandraMNE>`.

- |Fix| The metric :func:`metrics.r2_score` is degenerate with a single sample
  and now it returns NaN and raises :class:`exceptions.UndefinedMetricWarning`.
  :issue:`12855` by :user:`Pawel Sendyk <psendyk>.`

- |Efficiency| The pairwise manhattan distances with sparse input now uses the
  BLAS shipped with scipy instead of the bundled BLAS. :issue:`12732` by
  :user:`J√©r√©mie du Boisberranger <jeremiedbb>`

:mod:`sklearn.model_selection`
..............................

- |Feature| Classes :class:`~model_selection.GridSearchCV` and
  :class:`~model_selection.RandomizedSearchCV` now allow for refit=callable
  to add flexibility in identifying the best
  estimator. An example for this interface has been added.
  :issue:`11354` by :user:`Wenhao Zhang <wenhaoz@ucla.edu>`,
  `Joel Nothman`_ and :user:`Adrin Jalali <adrinjalali>`.

- |Enhancement| Classes :class:`~model_selection.GridSearchCV`,
  :class:`~model_selection.RandomizedSearchCV`, and methods
  :func:`~model_selection.cross_val_score`,
  :func:`~model_selection.cross_val_predict`,
  :func:`~model_selection.cross_validate`, now print train scores when
  `return_train_scores` is True and `verbose` > 2. For
  :func:`~model_selection.learning_curve`, and
  :func:`~model_selection.validation_curve` only the latter is required.
  :issue:`12613` and :issue:`12669` by :user:`Marc Torrellas <marctorrellas>`.

- |Fix| Fixed a bug where :class:`model_selection.StratifiedKFold`
  shuffles each class's samples with the same ``random_state``,
  making ``shuffle=True`` ineffective.
  :issue:`13124` by :user:`Hanmin Qin <qinhanmin2014>`.

:mod:`sklearn.neighbors`
........................

- |MajorFeature| A metric learning algorithm:
  :class:`neighbors.NeighborhoodComponentsAnalysis`, which implements the
  Neighborhood Components Analysis algorithm described in Goldberger et al.
  (2005). :issue:`10058` by :user:`William de Vazelhes
  <wdevazelhes>` and :user:`John Chiotellis <johny-c>`.

- |API| Methods in :class:`neighbors.NearestNeighbors` :
  :func:`~neighbors.NearestNeighbors.kneighbors`,
  :func:`~neighbors.NearestNeighbors.radius_neighbors`,
  :func:`~neighbors.NearestNeighbors.kneighbors_graph`,
  :func:`~neighbors.NearestNeighbors.radius_neighbors_graph`
  now raise ``NotFittedError``, rather than ``AttributeError``,
  when called before ``fit`` :issue:`12279` by :user:`Krishna Sangeeth
  <whiletruelearn>`.

- |API| Changing the parameter pattern in :class:`neighbors.KernelDensity` from
  ``metric = euclidean`` to ``metric = minkowski``. In addition to creating the
  parameter ``p = 2``. This p is that it should be possible to switch between
  Manhattan and Euclidian and other Minkowski distances just by modifying
  ``'p'`` (without changing metric).
  :issue:`12437` by :user:`Gilberto Olimpio <gilbertoolimpio>`

:mod:`sklearn.neural_network`
.............................

- |Fix| Fixed a bug in :class:`neural_network.MLPClassifier` and
  :class:`neural_network.MLPRegressor` where the option :code:`shuffle=False`
  was being ignored. :issue:`12582` by :user:`Sam Waterbury <samwaterbury>`.

:mod:`sklearn.pipeline`
.......................

- |API| :class:`pipeline.Pipeline` now supports using ``'passthrough'`` as a
  transformer. :issue:`11144` by :user:`Thomas Fan <thomasjpfan>`.

:mod:`sklearn.preprocessing`
............................

- |Efficiency| Make :class:`preprocessing.MultiLabelBinarizer` to cache class
  mappings instead of calculating it every time on the fly.
  :issue:`12116` by :user:`Ekaterina Krivich <kiote>` and `Joel Nothman`_.

- |Efficiency| :class:`preprocessing.PolynomialFeatures` now supports compressed
  sparse row (CSR) matrices as input for degrees 2 and 3. This is typically much
  faster than the dense case as it scales with matrix density and expansion degree
  (on the order of density^degree), and is much, much faster than the compressed
  sparse column (CSC) case. :issue:`12197` by :user:`Andrew Nystrom <awnystrom>`.

- |Efficiency| |API| Speed improvement in :class:`preprocessing.PolynomialFeatures`,
  in the dense case. Also added a new parameter ``order`` which controls output
  order for further speed performances. :issue:`12251` by `Tom Dupre la Tour`_.

- |Fix| Fixed the calculation overflow when using a float16 dtype with
  :class:`preprocessing.StandardScaler`. :issue:`13007` by
  :user:`Raffaello Baluyot <baluyotraf>`

- |Feature| :class:`OneHotEncoder` now supports dropping one feature per category
  with a new drop parameter. :issue:`12908` by
  :user:`Drew Johnston <drewmjohnston>`.


:mod:`sklearn.tree`
...................
- |Feature| Decision Trees can now be plotted with matplotlib using
  :func:`tree.plot_tree` without relying on the ``dot`` library,
  removing a hard-to-install dependency. :issue:`8508` by `Andreas M√ºller`_.

- |Feature| Decision Trees can now be exported in a human readable
  textual format using :func:`tree.export.export_text`.
  :issue:`6261` by `Giuseppe Vettigli <JustGlowing>`.

- |Feature| ``get_n_leaves()`` and ``get_depth()`` have been added to
  :class:`tree.BaseDecisionTree` and consequently all estimators based
  on it, including :class:`tree.DecisionTreeClassifier`,
  :class:`tree.DecisionTreeRegressor`, :class:`tree.ExtraTreeClassifier`,
  and :class:`tree.ExtraTreeRegressor`.
  :issue:`12300` by :user:`Adrin Jalali <adrinjalali>`.

- |Fix| Fixed an issue with :class:`tree.BaseDecisionTree`
  and consequently all estimators based
  on it, including :class:`tree.DecisionTreeClassifier`,
  :class:`tree.DecisionTreeRegressor`, :class:`tree.ExtraTreeClassifier`,
  and :class:`tree.ExtraTreeRegressor`, where they used to exceed the given
  ``max_depth`` by 1 while expanding the tree if ``max_leaf_nodes`` and
  ``max_depth`` were both specified by the user. Please note that this also
  affects all ensemble methods using decision trees.
  :issue:`12344` by :user:`Adrin Jalali <adrinjalali>`.

:mod:`sklearn.mixture`
......................

- |Fix| Fixed a bug in :class:`mixture.BaseMixture` and therefore on estimators
  based on it, i.e. :class:`mixture.GaussianMixture` and
  :class:`mixture.BayesianGaussianMixture`, where ``fit_predict`` and
  ``fit.predict`` were not equivalent. :issue:`13142` by
  :user:`J√©r√©mie du Boisberranger <jeremiedbb>`.


:mod:`sklearn.isotonic`
.......................

- |Feature| Allow different dtypes (such as float32) in
  :class:`isotonic.IsotonicRegression` :issue:`8769` by :user:`Vlad Niculae <vene>`

:mod:`sklearn.svm`
..................

- |Fix| Fixed an issue in :func:`svm.SVC.decision_function`
  when ``decision_function_shape='ovr'``. The decision_function value of a given
  sample was different depending on whether the decision_function was evaluated
  on the sample alone or on a batch containing this same sample due to the scaling
  used in decision_function. :pr:`10440` by :user:`Jonathan Ohayon <Johayon>`.

:mod:`sklearn.multiclass`
.........................

- |Fix| Fixed an issue in :func:`multiclass.OneVsOneClassifier.decision_function`
  where the decision_function value of a given sample was different depending on
  whether the decision_function was evaluated on the sample alone or on a batch
  containing this same sample due to the scaling used in decision_function.
  :pr:`10440` by :user:`Jonathan Ohayon <Johayon>`.

Multiple modules
................

- The `__repr__()` method of all estimators (used when calling
  `print(estimator)`) has been entirely re-written, building on Python's
  pretty printing standard library. All parameters are printed by default,
  but this can be altered with the ``print_changed_only`` option in
  :func:`sklearn.set_config`. :issue:`11705` by :user:`Nicolas Hug
  <NicolasHug>`.

Changes to estimator checks
---------------------------

These changes mostly affect library developers.

- Add ``check_fit_idempotent`` to
  :func:`~utils.estimator_checks.check_estimator`, which checks that
  when `fit` is called twice with the same data, the ouput of
  `predict`, `predict_proba`, `transform`, and `decision_function` does not
  change. :issue:`12328` by :user:`Nicolas Hug <NicolasHug>`
